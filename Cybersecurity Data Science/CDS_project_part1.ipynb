{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd6iFKF2gohh"
      },
      "source": [
        "# **CDS Project: Part 1**\n",
        "\n",
        "*Institute of Software Security (E22)*  \n",
        "*Hamburg University of Technology*  \n",
        "*SoSe 2023*\n",
        "\n",
        "## Learning objectives\n",
        "---\n",
        "\n",
        "- Use a basic Machine Learning (ML) pipeline with pre-trained models.\n",
        "- Build your own data loader.\n",
        "- Load and run a pre-trained ML model.\n",
        "- Evaluate the performance of an ML model.\n",
        "- Calculate and interpret performance metrics.\n",
        "\n",
        "## Materials\n",
        "---\n",
        "\n",
        "- Lecture Slides 1, 2, and 3.\n",
        "- PyTorch Documentation: [Datasets and Data Loaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybWt0W4gjbiC"
      },
      "source": [
        "## Project Description\n",
        "---\n",
        "\n",
        "In this project, you are given an ML model that is pre-trained on a vulnerability dataset. The dataset consists of code samples labeled with True or False flags, depending on the presence and absense of a vulnerability. Your goal is to use the pre-trained model to predict if the code samples in the validation set contain vulnerabilities or not and analyse the results. Please proceed to the below tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrciLvqNj96k"
      },
      "source": [
        "###*Task 1*\n",
        "\n",
        "Build a data loader for the validation dataset present in the following path: \"*data_students/student_dataset.hdf5*\". You will be using this dataset to validate the performance of the ML model. The dataset is in HDF5 binary data format. This format is used to store large amount of data. Make sure that you import and familiarise yourself with the right Python libraries to handle HDF5 files. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially, we import the torch and h5py libraries and view the structure of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Eem6AZNyyXsn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels\n",
            "source\n",
            "vectors\n"
          ]
        }
      ],
      "source": [
        "#Import Libraries\n",
        "import numpy as np #Numerical Manipulation\n",
        "import torch #Neural Network Training\n",
        "import h5py #Load, Manipulation of .hdf5 files\n",
        "from torch.utils.data import Dataset #Conversion into tensor format\n",
        "from torch.utils.data import DataLoader #Loading the Data into the pre-trained Model\n",
        "import pandas as pd #Exploratory Data analysis\n",
        "from torch import nn #Task4\n",
        "from sklearn.metrics import confusion_matrix #For TP, TN, FP, FN computation\n",
        "\n",
        "#Check datasets at root\n",
        "def print_structure(name, obj):\n",
        "    print(name)    \n",
        "    \n",
        "f = h5py.File('./data_students/student_dataset.hdf5', 'r')\n",
        "f.visititems(print_structure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we check the shape of the data for further information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels shape: (1000,)\n",
            "source shape: (1000,)\n",
            "vectors shape: (1000, 1, 768)\n"
          ]
        }
      ],
      "source": [
        "with h5py.File('./data_students/student_dataset.hdf5', 'r') as f:\n",
        "    for name in f:\n",
        "        print(f\"{name} shape: {f[name].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We proceed by loading the data into variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "with h5py.File('./data_students/student_dataset.hdf5', 'r') as f:\n",
        "    vectors = np.squeeze(f[\"vectors\"][:])  \n",
        "    labels = f[\"labels\"][:]               \n",
        "    source = f[\"source\"][:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Towards using this data with Pytorch, we create a custom class to load the data in tensor form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Custom Class to load data into Tensor format for Pytorch\n",
        "class StudentDataset(Dataset):\n",
        "    def __init__(self, vectors, labels, source):\n",
        "        self.vectors = torch.tensor(vectors, dtype = torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype = torch.float32)\n",
        "        self.source = source\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return{\n",
        "            'vector': self.vectors[idx],\n",
        "            'label': self.labels[idx],\n",
        "            'source': self.source[idx]\n",
        "        }\n",
        "        \n",
        "#Create custom tensor dataset using StudentDataset class\n",
        "dataset = StudentDataset(vectors, labels, source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARwcBrbFlMu8"
      },
      "source": [
        "###*Task 2*\n",
        "\n",
        "Generate a table with 10 random samples from the dataset and show their corresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use pandas to create the table for exploratory data analysis on the dataset object.\n",
        "Note \n",
        "- The vector embedding is truncated to 5 dimensions for the purpose of easy viewing.\n",
        "- The boolean value in label will be presented categorically (1 or 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "AuYminA_mTnJ"
      },
      "outputs": [],
      "source": [
        "#Creating a Data Dictionary for the dataset\n",
        "data_dict = {\n",
        "    \"Text\": [dataset[i][\"source\"] for i in range(len(dataset))],\n",
        "    \"Label\": [int(dataset[i][\"label\"].item()) for i in range(len(dataset))],\n",
        "    \"Vector (truncated)\": [dataset[i][\"vector\"][:5].tolist() for i in range(len(dataset))] \n",
        "}\n",
        "\n",
        "#Constructing a Pandas dataframe\n",
        "df = pd.DataFrame(data_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then print the top 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Vector (truncated)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'get_charcode(VMG_ uint argc)\\r\\n{\\r\\n    con...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0354700088500977, -0.21910110116004944, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b\"find_open_file_info(char * id) {\\n    unsign...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.7009735703468323, -0.33198848366737366, -2....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'_openipmi_read (ipmi_openipmi_ctx_t ctx,\\n  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.16170060634613037, 1.011047601699829, -0.54...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'camel_store_get_inbox_folder_sync (CamelStor...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.2847437858581543, -0.02586905099451542, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b\"locate_var_of_level_walker(Node *node,\\n\\t\\t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.6463299989700317, 0.8318526148796082, -0.17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b'apply(ast_sent* s) {\\n        if (s-&gt;get_nod...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.14187678694725037, -0.05534656345844269, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>b'addr_ston(const struct sockaddr *sa, struct ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1.5827864408493042, 0.11386679857969284, -1.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b'printStats(const RunSummary&amp; sol, const Solv...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.7642837762832642, 1.819999098777771, -0.90...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>b'extendtimeline() {\\n  if (timeline.recording...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.7471140623092651, -1.333551287651062, 0.72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b'Document(Conf&amp; conf, Encodings&amp; encodings, i...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.4751206636428833, -1.2725929021835327, -0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Label  \\\n",
              "0  b'get_charcode(VMG_ uint argc)\\r\\n{\\r\\n    con...      0   \n",
              "1  b\"find_open_file_info(char * id) {\\n    unsign...      0   \n",
              "2  b'_openipmi_read (ipmi_openipmi_ctx_t ctx,\\n  ...      1   \n",
              "3  b'camel_store_get_inbox_folder_sync (CamelStor...      1   \n",
              "4  b\"locate_var_of_level_walker(Node *node,\\n\\t\\t...      0   \n",
              "5  b'apply(ast_sent* s) {\\n        if (s->get_nod...      0   \n",
              "6  b'addr_ston(const struct sockaddr *sa, struct ...      1   \n",
              "7  b'printStats(const RunSummary& sol, const Solv...      0   \n",
              "8  b'extendtimeline() {\\n  if (timeline.recording...      0   \n",
              "9  b'Document(Conf& conf, Encodings& encodings, i...      0   \n",
              "\n",
              "                                  Vector (truncated)  \n",
              "0  [1.0354700088500977, -0.21910110116004944, -0....  \n",
              "1  [0.7009735703468323, -0.33198848366737366, -2....  \n",
              "2  [0.16170060634613037, 1.011047601699829, -0.54...  \n",
              "3  [1.2847437858581543, -0.02586905099451542, -0....  \n",
              "4  [1.6463299989700317, 0.8318526148796082, -0.17...  \n",
              "5  [0.14187678694725037, -0.05534656345844269, -0...  \n",
              "6  [1.5827864408493042, 0.11386679857969284, -1.0...  \n",
              "7  [-0.7642837762832642, 1.819999098777771, -0.90...  \n",
              "8  [-0.7471140623092651, -1.333551287651062, 0.72...  \n",
              "9  [1.4751206636428833, -1.2725929021835327, -0.0...  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5YCWVkmUL2"
      },
      "source": [
        "###*Task 3*\n",
        "\n",
        "Inspect the dataset and answer the following questions:\n",
        "1.  How many samples are in the dataset?\n",
        "2. How many positive examples (vulnerability-labeled instances) are in the dataset?\n",
        "3. What is the vulnerable/non-vulnerable ratio?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "LDpozMCfnnJg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Count: 1000\n",
            "Positive Example Count (Label - 1): 283\n",
            "Vulnerable/Non-Vulnerable Ratio: 0.3947001394700139\n"
          ]
        }
      ],
      "source": [
        "#Answer 1 - Sample Count\n",
        "sample_count = df.count()\n",
        "\n",
        "#Answer 2 - Positive Example Count (Label - 1)\n",
        "positive_examples = (df['Label'] == 1).sum()\n",
        "\n",
        "#Answer 3 - Calculate Vulnerable/Non-Vulnerable Ratio\n",
        "vulnerability_ratio = (df['Label'] == 1).sum()/(df['Label'] == 0).sum()\n",
        "\n",
        "#Consolidated Answer\n",
        "print(f\"Sample Count: {sample_count.iloc[0]}\")\n",
        "print(f\"Positive Example Count (Label - 1): {positive_examples}\")\n",
        "print(f\"Vulnerable/Non-Vulnerable Ratio: {vulnerability_ratio}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UivWlO3dnngr"
      },
      "source": [
        "###*Task 4*\n",
        "\n",
        "Load and run the following pre-trained neural network model called VulnPredictionModel. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jex8XdkFJhb"
      },
      "source": [
        "``` python \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RrGtLkpEzKu"
      },
      "source": [
        "``` python\n",
        "from torch import nn\n",
        "\n",
        "class VulnPredictModel(nn.Module):\n",
        "    # intialize the model architecture\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_stack = nn.Sequential(\n",
        "         nn.Linear(768, 64),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(64, 64),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(64, 1),\n",
        "         nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "      # forward propagation\n",
        "      def forward(self, x):\n",
        "        pred = self.linear_stack(x)\n",
        "        return pred\n",
        "      \n",
        "\n",
        "# TODO: intialize and load the model\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin by running the provided code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class VulnPredictModel(nn.Module):\n",
        "    # intialize the model architecture\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_stack = nn.Sequential(\n",
        "         nn.Linear(768, 64),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(64, 64),\n",
        "         nn.ReLU(),\n",
        "         nn.Linear(64, 1),\n",
        "         nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "      pred = self.linear_stack(x)\n",
        "      return pred     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create an instance of the model, load the weights, and then load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pre-trained model weights.\n",
            "Model Inference Complete.\n"
          ]
        }
      ],
      "source": [
        "#Instantiate the Model\n",
        "model = VulnPredictModel()\n",
        "\n",
        "#Load the Weights\n",
        "try:\n",
        "    model.load_state_dict(torch.load('model_2023-03-28_20-03.pth', map_location=device))\n",
        "    print(\"Loaded pre-trained model weights.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Model weights file not found. Proceeding with untrained model.\")\n",
        "    \n",
        "#Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#Running Inference on the provided data.\n",
        "\n",
        "#Step 1 - Create DataLoader with appropriate batch_size\n",
        "batch_size = 32 \n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#Step 2 - Perform Inference using Model on provided data\n",
        "predictions = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        vectors = batch['vector'].to(device)\n",
        "        batch_labels = batch['label'].to(device)\n",
        "        \n",
        "        #Perform forward pass\n",
        "        outputs = model.forward(vectors)\n",
        "        \n",
        "        #Apply threshold for Binary Classification (from Sigmoidal Output in final layer)\n",
        "        prediction = (outputs > 0.5).float().cpu().numpy()\n",
        "        predictions.extend(prediction)\n",
        "        \n",
        "        #Simulataneously store actual labels in the label list\n",
        "        labels.extend(batch_labels)\n",
        "        \n",
        "print(\"Model Inference Complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A9M9ID0n2Gx"
      },
      "source": [
        "###*Task 5*\n",
        "\n",
        "Make a prediction on the provided dataset and compute the following values:\n",
        "- True Positives\n",
        "- True Negatives\n",
        "- False Positives\n",
        "- False Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "R8KdeQ2Rn-2Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positive Count : 20\n",
            "True Negative Count : 1\n",
            "False Positive Count : 263\n",
            "True Negative Count : 20\n"
          ]
        }
      ],
      "source": [
        "# Interpretation \n",
        "# True Positive - Both Model prediction and Dataset have same value, for positive vulnerability.- TP\n",
        "# True Negative - Both Model prediction and Dataset have same value, for no vulnerability. - TN\n",
        "# False Positive - Both Model prediction and Dataset have differing value, for positive vulnerability. - FP\n",
        "# False Negative - Both Model prediction and Dataset have differing value, for no vulnerability. - FN\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "# Unravel the confusion matrix\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "# Present Results\n",
        "print(f\"True Positive Count : {TP}\")\n",
        "print(f\"True Negative Count : {FP}\")\n",
        "print(f\"False Positive Count : {FN}\")\n",
        "print(f\"True Negative Count : {TP}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaFHwiVwow7s"
      },
      "source": [
        "### *Task 6*\n",
        "\n",
        "Compute the corresponding performance metrics **manually** (do not use PyTorch's predefined metrics):\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "KE2daH3LpGEc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7360\n",
            "Precision: 0.9524\n",
            "Recall: 0.0707\n",
            "Specificity: 0.9986\n",
            "F1 Score: 0.1316\n"
          ]
        }
      ],
      "source": [
        "# Calculate Metrics\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Display Metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdIkKUPlpGjv"
      },
      "source": [
        "### *Task 7*\n",
        "\n",
        "Based on your performance metrics, answer the following questions:\n",
        "\n",
        "- Explain the impact of accuracy vs. F1 score.\n",
        "- In this particular problem, which metric one should focus more on?\n",
        "- Is there a better metric suitable for the use case of vulnerability prediction? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Miscellaneous Code-Bits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: import the necessary libraries to load the data from the specified path.\n",
        "\n",
        "# SOLUTION: \n",
        "\n",
        "#Libraries Import\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "#Load Dataset using h5py library\n",
        "f = h5py.File('./data_students/student_dataset.hdf5')\n",
        "labels = f['labels'][:]\n",
        "sources = f['source'][:]\n",
        "vectors = f['vectors'][:]\n",
        "f.close()\n",
        "\n",
        "#Access and Print First index to confirm proper loading\n",
        "label0, source0, vector0 = labels[0], sources[0], vectors[0]\n",
        "print(f\"Label: {label0}, Vector: {vector0}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "labs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
